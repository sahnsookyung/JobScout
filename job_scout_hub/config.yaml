database:
  url: "postgresql://user:password@postgres:5432/jobscout"

jobspy:
  url: "http://jobspy-service:8000" # This is the container for JobSpy and the URL when using Docker to run JobScout
  # url: "http://localhost:8000" # This is the host for JobSpy when running main.py locally

etl:
  mock: false # Using local AI stack
  llm:
    # Ollama for embeddings (OpenAI-compatible API)
    base_url: "http://ollama:11434/v1"
    api_key: "ollama" # Dummy key for local Ollama
    
    # Extraction
    extraction_url: "" # Not used for Ollama/OpenAI
    extraction_type: "ollama" # Use "openai", "ollama" or "mock"
    extraction_model: "qwen3:14b"
    
    # Model configurations
    embedding_model: "qwen3-embedding:4b"
    embedding_dimensions: 1024 # qwen3-embedding:4b uses 1024 dimensions
    
    # GLiNER extraction labels (aligned with SRS)
    extraction_labels:
      - "programming_language"
      - "framework"
      - "tool"
      - "platform"
      - "skill"
      - "experience_years"
      - "education_degree"
      - "certification"
      - "responsibility"
      - "benefit"

schedule:
  interval_seconds: 3600  # Run every hour

scrapers:
  - site_type: ["tokyodev"]
    search_term: "python"
    results_wanted: 5
    options:
      seniorities: ["intern", "junior", "intermediate"]
      
  - site_type: ["japandev"]
    search_term: ""
    results_wanted: 5
    options:
      japanese_levels: ["japanese_level_not_required"]

  - site_type: ["indeed"]
    search_term: "software engineer"
    location: "Tokyo"
    results_wanted: 5
    hours_old: 24

  - site_type: ["glassdoor"]
    search_term: "software engineer"
    location: "Tokyo"
    results_wanted: 5
    hours_old: 24
