database:
  url: "postgresql://user:password@postgres:5432/jobscout"

jobspy:
  url: "http://jobspy-service:8000" # This is the container for JobSpy and the URL when using Docker to run JobScout
  # url: "http://localhost:8000" # This is the host for JobSpy when running main.py locally

etl:
  mock: true # Set to false to use real OpenAI API
  llm:
    base_url: null # Set to local endpoint like "http://localhost:11434/v1" for Ollama
    api_key: null # Optional for local models, required for OpenAI
    extraction_model: "gpt-4o-mini"
    embedding_model: "text-embedding-3-small"
    embedding_dimensions: 768

schedule:
  interval_seconds: 3600  # Run every hour

scrapers:
  - site_type: ["tokyodev"]
    search_term: "python"
    results_wanted: 5
    options:
      seniorities: ["intern", "junior", "intermediate"]
      
  - site_type: ["japandev"]
    search_term: ""
    results_wanted: 5
    options:
      japanese_levels: ["japanese_level_not_required"]

  - site_type: ["indeed"]
    search_term: "software engineer"
    location: "Tokyo"
    results_wanted: 5
    hours_old: 24

  - site_type: ["glassdoor"]
    search_term: "software engineer"
    location: "Tokyo"
    results_wanted: 5
    hours_old: 24
